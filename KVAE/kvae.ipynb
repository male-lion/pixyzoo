{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman VAE\n",
    "- Original paper: A Disentangled Recognition and Nonlinear DynamicsModel for Unsupervised Learning (https://arxiv.org/pdf/1710.05741.pdf)\n",
    "- Original code: https://github.com/simonkamronn/kvae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kalman VAE summary\n",
    ">KVAE disentangles two latent representations: an object’s representation, coming from a recognition model, and a latent state describing its dynamics. As a result, the evolution of the world can be imagined and missing data imputed, both without the need to generate high dimensional frames at each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "from pixyz.utils import print_latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3a6c079d90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 1\n",
    "seed = 1\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate MNIST by stacking row images(consider row as time step)\n",
    "def init_dataset(f_batch_size):\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "    data_dir = '../data'\n",
    "    mnist_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda data: data[0])\n",
    "    ])\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(data_dir, train=True, download=True,\n",
    "                       transform=mnist_transform),\n",
    "        batch_size=f_batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(data_dir, train=False, transform=mnist_transform),\n",
    "        batch_size=f_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "    fixed_t_size = 28\n",
    "    return train_loader, test_loader, fixed_t_size\n",
    "\n",
    "train_loader, test_loader, t_max = init_dataset(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define probability distributions\n",
    "### In the original paper\n",
    "Prior: $p_{\\gamma}({\\bf a}|{\\bf u}) = {\\int p_{\\gamma}({\\bf a}|{\\bf z})p_{\\gamma}({\\bf z}|{\\bf u})d{\\bf z}}$ (equation (3) in the paper)\n",
    "\n",
    "Generator: $p_{\\theta}({\\bf x}|{\\bf a}) = \\prod_{t=1}^{T}p_{\\theta}(x_t | a_t)$  \n",
    ">$p_{\\theta}(x_t|a_t)$ is a deep neural network parameterized by θ, that emits either a factorized Gaussian or Bernoulli probability vector depending on the data type of $x_t$.\n",
    "\n",
    "Inference:  $q_{\\phi}({\\bf a}|{\\bf x}) = \\prod_{t=1}^{T}q_{\\phi}(a_t | x_t)$  \n",
    "$q_{\\phi}(a_t | x_t) = {\\cal N}(\\mu_{\\phi}(x_t), \\Sigma_{\\phi}(x_t))$\n",
    ">$q_{\\phi}(a_t|x_t)$ is a deep neural network that maps xt to the mean and the diagonal covariance of a Gaussian distribution.  \n",
    "\n",
    "LGSSM:  \n",
    "$p_{\\gamma_{t}}\\left(\\mathbf{z}_{t} | \\mathbf{z}_{t-1}, \\mathbf{u}_{t}\\right)=\\mathcal{N}\\left(\\mathbf{z}_{t} ; \\mathbf{A}_{t} \\mathbf{z}_{t-1}+\\mathbf{B}_{t} \\mathbf{u}_{t}, \\mathbf{Q}\\right), \\quad p_{\\gamma_{t}}\\left(\\mathbf{a}_{t} | \\mathbf{z}_{t}\\right)=\\mathcal{N}\\left(\\mathbf{a}_{t} ; \\mathbf{C}_{t} \\mathbf{z}_{t}, \\mathbf{R}\\right)$ (equation (1) in the paper)\n",
    "\n",
    "$p_{\\gamma}(\\mathbf{a}, \\mathbf{z} | \\mathbf{u})=\\prod_{t=1}^{T} p_{\\gamma_{t}}\\left(\\mathbf{a}_{0: t-1}\\right)\\left(\\mathbf{a}_{t} | \\mathbf{z}_{t}\\right) \\cdot p\\left(\\mathbf{z}_{1}\\right) \\prod_{t=2}^{T} p_{\\gamma_{t}\\left(\\mathbf{a}_{0: t-1}\\right)}\\left(\\mathbf{z}_{t} | \\mathbf{z}_{t-1}, \\mathbf{u}_{t}\\right)$ (equation (8) in the paper)\n",
    "\n",
    "dynamics parameter network: \n",
    "${\\bf \\alpha}_t = {\\bf \\alpha}_t(a_{0:t-1})$  \n",
    "${\\bf d}_t = LSTM(a_{t-1}, d_{t-1})$  \n",
    "${\\bf \\alpha}_t = softmax({\\bf d}_t)$\n",
    "$\\mathbf{A}_{t}=\\sum_{k=1}^{K} \\alpha_{t}^{(k)}\\left(\\mathbf{a}_{0: t-1}\\right) \\mathbf{A}^{(k)}, \\quad \\mathbf{B}_{t}=\\sum_{k=1}^{K} \\alpha_{t}^{(k)}\\left(\\mathbf{a}_{0: t-1}\\right) \\mathbf{B}^{(k)}, \\quad \\mathbf{C}_{t}=\\sum_{k=1}^{K} \\alpha_{t}^{(k)}\\left(\\mathbf{a}_{0: t-1}\\right) \\mathbf{C}^{(k)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実装するやつ\n",
    "Prior: \n",
    "$p_{\\gamma}(a_{t\\_pred} | C_t, z_{mu\\_t\\_pred}, R)$\n",
    "\n",
    "Generator: \n",
    "$p_{\\theta}(x_t | a_t)$\n",
    "\n",
    "Inference: \n",
    "$q_{\\phi}(a_t | x_t)$\n",
    "\n",
    "Dynamics parameter network ($LSTM(d_t |a_{t-1}, d_{t-1})$含む):  \n",
    "$p_{\\gamma}(A_t, B_t, C_t | a_{0:t-1})$\n",
    "\n",
    "z_prediction(Transition):  \n",
    "$p_{\\gamma}(z_{mu\\_t\\_pred}, z_{sigma\\_t\\_pred} | At, Bt, u_t, z_{mu\\_prev}, z_{sigma\\_prev})$\n",
    "\n",
    "filter:\n",
    "$p_{\\gamma}(z_{mu\\_t}, z_{sigma\\_t} | C_t, a_{t\\_pred}, a_t, z_{mu\\_t\\_pred}, z_{sigma\\_t\\_pred})$\n",
    "\n",
    "smooth:\n",
    "確認中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/simonkamronn/kvae/blob/849d631dbf2faf2c293d56a0d7a2e8564e294a51/kvae/KalmanVariationalAutoencoder.py#L97\n",
    "\n",
    "from pixyz.distributions import Normal\n",
    "class Inference(Normal):\n",
    "    def __init__(self, x_dim, a_dim):\n",
    "        super(Inference, self).__init__(name=\"q_phi\", cond_var=[\"x_t\"], var=[\"a_t\"])\n",
    "        self.fc1 = nn.Linear(x_dim, 25)\n",
    "        self.fc2 = nn.Linear(25, 25)\n",
    "        \n",
    "        self.fc3_1 = nn.Linear(25, a_dim)\n",
    "        self.fc3_2 = nn.Linear(25, a_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return {\"loc\": self.fc3_1(h), \"scale\": F.softplus(self.fc3_2(h))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$q_{\\phi}(a_{t}|x_{t})$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Inference(44, 44)\n",
    "print_latex(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/simonkamronn/kvae/blob/849d631dbf2faf2c293d56a0d7a2e8564e294a51/kvae/KalmanVariationalAutoencoder.py#L132\n",
    "\n",
    "from pixyz.distributions import Bernoulli\n",
    "class Generator(Bernoulli):\n",
    "    def __init__(self, a_dim, x_dim):\n",
    "        super(Generator, self).__init__(name=\"p_theta\", cond_var=[\"a_t\"], var=[\"x_t\"])\n",
    "        self.fc1 = nn.Linear(a_dim, 25)\n",
    "        self.fc2 = nn.Linear(25, 25)\n",
    "        \n",
    "        self.fc3 = nn.Linear(25, x_dim)\n",
    "    \n",
    "    def forward(self, a):\n",
    "        h = F.relu(self.fc1(a))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return {\"probs\": torch.sigmoid(self.fc3(h))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$p_{\\theta}(x_{t}|a_{t})$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = Generator(44, 44)\n",
    "print_latex(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/simonkamronn/kvae/blob/849d631dbf2faf2c293d56a0d7a2e8564e294a51/kvae/KalmanVariationalAutoencoder.py#L176\n",
    "\n",
    "from pixyz.distributions import Deterministic\n",
    "class RNN(Deterministic):\n",
    "    def __init__(self, a_dim, d_dim):\n",
    "        super(RNN, self).__init__(name=\"LSTM\", cond_var=[\"a_prev\", \"d_prev\"], var=[\"d\"])\n",
    "        # d_dim = 50\n",
    "        self.rnn = nn.LSTMCell(a_dim, d_dim)\n",
    "        \n",
    "    def forward(self, a_prev, d_prev):\n",
    "        h, _ = self.rnn(a_prev, d_prev)\n",
    "        return {\"d\": h}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/simonkamronn/kvae/blob/849d631dbf2faf2c293d56a0d7a2e8564e294a51/kvae/KalmanVariationalAutoencoder.py#L220\n",
    "\n",
    "from pixyz.distributions import Deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$LSTM(d|a_{prev},d_{prev})$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = RNN(10, 50)\n",
    "print_latex(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/simonkamronn/kvae/blob/849d631dbf2faf2c293d56a0d7a2e8564e294a51/kvae/KalmanVariationalAutoencoder.py#L220\n",
    "\n",
    "from pixyz.distributions import Deterministic\n",
    "class DynamicParameterNetwork(Deterministic):\n",
    "    def __init__(self, d_dim, k_num):\n",
    "        super(DynamicParameterNetwork, self).__init__(name=\"p_alpha\", cond_var=[\"d\"], var=[\"alpha\"])\n",
    "        self.fc1 = nn.Linear(d_dim, k_num)\n",
    "        \n",
    "    def forward(self, d):\n",
    "        return {\"alpha\": F.softmax(self.fc1(d))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$p_{\\alpha}(\\alpha|d)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = DynamicParameterNetwork(50, 3)\n",
    "print_latex(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$p(\\alpha,d|a_{prev},d_{prev}) = p_{\\alpha}(\\alpha|d)LSTM(d|a_{prev},d_{prev})$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dynamic = a * r\n",
    "print_latex(Dynamic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-15-05d5b26e194a>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-05d5b26e194a>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    class KalmanFilter()\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# LGSSM P(a, z | u)\n",
    "class KalmanFilter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class z(Normal):\n",
    "    def __init__(self):\n",
    "        super(z, self).__init__(var=[\"z\"])\n",
    "    def forward(self):\n",
    "        return {\"loc\": 0, \"scale\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = z()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$p(z)$$"
      ],
      "text/plain": [
       "<IPython.core.display.Math object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_latex(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'z': tensor(2.0017)}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/simonkamronn/kvae/blob/849d631dbf2faf2c293d56a0d7a2e8564e294a51/kvae/filter.py#L82\n",
    "class Kalamn_a_given_z(Normal):\n",
    "    def __init__(self, z_dim, a_dim, k_dim):\n",
    "        super(Kalamn_a_given_z, self).__init__(name=\"p_gamma\", cond_var=[\"alpha\", \"z\"], var=[\"a_pred\"])\n",
    "        \n",
    "        self.z_dim = z_dim\n",
    "        self.a_dim = a_dim\n",
    "        self.k_dim = k_dim\n",
    "        \n",
    "        self.C = torch.tensor(np.array([0.05 * np.random.randn(self.a_dim, self.z_dim).astype(np.float32) for _ in range(self.k_dim)]))\n",
    "        self.R = torch.tensor(0.03 * np.eye(self.dim_a, dtype=np.float32))\n",
    "        \n",
    "    def forward(self, alpha, z):\n",
    "        C = torch.matmul(alpha, torch.reshape(self.C, [-1, self.a_dim, self.z_dim])) # (bs, k) x (k, dim_y*dim_z)\n",
    "        C = torch.reshape(alpha, self.a_dim, self.z_dim)# (bs, dim_a, dim_z)\n",
    "        \n",
    "        # residual\n",
    "        a_pred = torch.squeeze(tf.matmul(C, torch.squeeze(z, 2))) # (bs, dim_a)\n",
    "        \n",
    "        return {\"a\": a_pred}\n",
    "\n",
    "    \n",
    "class kalman_z_given_u_z_t_prev(Normal):\n",
    "    def __init__(self, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kalman_a_given_z(Normal):\n",
    "    def __init__(self, z_dim, u_dim, k_dim):\n",
    "        super(Kalman_a_given_z, self).__init__(name=\"p_gamma\", cond_var=[\"alpha\", \"z_prev\", \"u\"], var=[\"z\"])\n",
    "        \n",
    "        self.z_dim = z_dim\n",
    "        self.u_dim = u_dim\n",
    "        self.k_dim = k_dim\n",
    "        \n",
    "        self.A = torch.tensor(np.array([np.eye(z_dim).astype(np.float32) for _ in range(k_dim)]))\n",
    "        \n",
    "        self.B = torch.tensor(np.array([0.05 * np.random.randn(z_dim, u_dim).astype(np.float32) for _ in range(k_dim)]))\n",
    "        \n",
    "        self.Q = torch.tensor(0.08 * np.eye(z_dim, dtype=np.float32))\n",
    "        \n",
    "    def forward(self, alpha, z_prev, u):\n",
    "        A = torch.matmul(alpha, torch.reshape(self.A, [-1, self.z_dim*self.z_dim]))  # (bs, k) x (k, dim_z*dim_z)\n",
    "        A = torch.reshape(A, [-1, self.z_dim, self.z_dim])  # (bs, dim_z, dim_z)\n",
    "        \n",
    "        \n",
    "        B = torch.matmul(alpha, torch.reshape(self.B, [-1, self.z_dim*self.u_dim]))  # (bs, k) x (k, dim_y*dim_z)\n",
    "        B = torch.reshape(B, [-1, self.z_dim, self.u_dim])  # (bs, dim_y, dim_z)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilter(object):\n",
    "    \"\"\"\n",
    "    This class defines a Kalman Filter (Linear Gaussian State Space Model), possibly with a dynamics\n",
    "    parater network alpha\n",
    "    \"\"\"\n",
    "    def __init__(self, batch_size, dim_z=4, dim_a=2, dim_u=1, dim_k=3):\n",
    "        self.batch_size = batch_size\n",
    "        self.dim_z = dim_z\n",
    "        self.dim_a = dim_a\n",
    "        self.dim_u = dim_u\n",
    "        self.dim_k = dim_k\n",
    "        \n",
    "        self.A = torch.tensor(np.array([np.eye(self.dim_z).astype(np.float32) for _ in range(self.dim_k)]))\n",
    "        \n",
    "        self.B = torch.tensor(np.array([0.05 * np.random.randn(self.dim_z, self.dim_u).astype(np.float32) for _ in range(self.dim_k)]))\n",
    "        \n",
    "        self.C = torch.tensor(np.array([0.05 * np.random.randn(self.dim_a, self.dim_z).astype(np.float32) for _ in range(self.dim_k)]))\n",
    "        \n",
    "        # We use isotropic covariance matrices\n",
    "        self.Q = torch.tensor(0.08 * np.eye(self.dim_z, dtype=np.float32))\n",
    "        self.R = torch.tensor(0.03 * np.eye(self.dim_a, dtype=np.float32))\n",
    "        \n",
    "        # p(z_1)\n",
    "        self.mu = torch.tensor(np.zeros((self.batch_size, self.dim_z), dtype=np.float32))\n",
    "        self.Sigma = torch.tensor(np.tile(20.0 * np.eye(self.dim_z, dtype=np.float32), (self.batch_size, 1, 1)))\n",
    "        \n",
    "        # Initial variable a_0\n",
    "        self.a_0 = torch.tensor(np.zeros((self.dim_a,), dtype=np.float32))\n",
    "        \n",
    "        self._alpha_sq = torch.tensor(1.)\n",
    "        # process-measurement cross correlation\n",
    "        self.M = 0\n",
    "        \n",
    "        # identity Matrix\n",
    "        self._I = torch.eye(dim_z)\n",
    "        "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[20.,  0.,  0.],\n",
       "        [ 0., 20.,  0.],\n",
       "        [ 0.,  0., 20.]],\n",
       "\n",
       "       [[20.,  0.,  0.],\n",
       "        [ 0., 20.,  0.],\n",
       "        [ 0.,  0., 20.]],\n",
       "\n",
       "       [[20.,  0.,  0.],\n",
       "        [ 0., 20.,  0.],\n",
       "        [ 0.,  0., 20.]]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(20.0 * np.eye(3, dtype=np.float32), (3, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.array([0.05 * np.random.randn(3, 2).astype(np.float32) for _ in range(5)])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0.],\n",
       "        [0., 1.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.zeros((3, )).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((3, )).shape\n",
    "torch.tensor(np.zeros((3, ))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Loss function\n",
    "$\\mathcal{F}(\\theta, \\gamma, \\phi)=\\mathbb{E}_{q_{\\phi}(\\mathbf{a} | \\mathbf{x})}\\left[\\log \\frac{p_{\\theta}(\\mathbf{x} | \\mathbf{a})}{q_{\\phi}(\\mathbf{a} | \\mathbf{x})}+\\mathbb{E}_{p_{\\gamma}(\\mathbf{z} | \\mathbf{a}, \\mathbf{u})}\\left[\\log \\frac{p_{\\gamma}(\\mathbf{a} | \\mathbf{z}) p_{\\gamma}(\\mathbf{z} | \\mathbf{u})}{p_{\\gamma}(\\mathbf{z} | \\mathbf{a}, \\mathbf{u})}\\right]\\right]$ (euqation (6) in the paper)\n",
    "\n",
    "$\\hat{\\mathcal{F}}(\\theta, \\gamma, \\phi)=\\frac{1}{I} \\sum_{i} \\log p_{\\theta}\\left(\\mathbf{x} | \\widetilde{\\mathbf{a}}^{(i)}\\right)+\\log p_{\\gamma}\\left(\\widetilde{\\mathbf{a}}^{(i)}, \\widetilde{\\mathbf{z}}^{(i)} | \\mathbf{u}\\right)-\\log q_{\\phi}\\left(\\widetilde{\\mathbf{a}}^{(i)} | \\mathbf{x}\\right)-\\log p_{\\gamma}\\left(\\widetilde{\\mathbf{z}}^{(i)} | \\widetilde{\\mathbf{a}}^{(i)}, \\mathbf{u}\\right)$ (euqation (7) in the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
