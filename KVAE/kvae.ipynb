{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman VAE\n",
    "- Original paper: A Disentangled Recognition and Nonlinear DynamicsModel for Unsupervised Learning (https://arxiv.org/pdf/1710.05741.pdf)\n",
    "- Original code: https://github.com/simonkamronn/kvae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kalman VAE summary\n",
    ">KVAE disentangles two latent representations: an object’s representation, coming from a recognition model, and a latent state describing its dynamics. As a result, the evolution of the world can be imagined and missing data imputed, both without the need to generate high dimensional frames at each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9e9e0b61d0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 1\n",
    "seed = 1\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate MNIST by stacking row images(consider row as time step)\n",
    "def init_dataset(f_batch_size):\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True}\n",
    "    data_dir = '../data'\n",
    "    mnist_transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda data: data[0])\n",
    "    ])\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(data_dir, train=True, download=True,\n",
    "                       transform=mnist_transform),\n",
    "        batch_size=f_batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(data_dir, train=False, transform=mnist_transform),\n",
    "        batch_size=f_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "    fixed_t_size = 28\n",
    "    return train_loader, test_loader, fixed_t_size\n",
    "\n",
    "train_loader, test_loader, t_max = init_dataset(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define probability distributions\n",
    "### In the original paper\n",
    "Prior: $p_{\\gamma}({\\bf a}|{\\bf u}) = {\\int p_{\\gamma}({\\bf a}|{\\bf z})p_{\\gamma}({\\bf z}|{\\bf u})d{\\bf z}}$ (equation (3) in the paper)\n",
    "\n",
    "Generator: $p_{\\theta}({\\bf x}|{\\bf a}) = \\prod_{t=1}^{T}p_{\\theta}(x_t | a_t)$  \n",
    ">$p_{\\theta}(x_t|a_t)$ is a deep neural network parameterized by θ, that emits either a factorized Gaussian or Bernoulli probability vector depending on the data type of $x_t$.\n",
    "\n",
    "Inference:  $q_{\\phi}({\\bf a}|{\\bf x}) = \\prod_{t=1}^{T}q_{\\phi}(a_t | x_t)$  \n",
    "$q_{\\phi}(a_t | x_t) = {\\cal N}(\\mu_{\\phi}(x_t), \\Sigma_{\\phi}(x_t))$\n",
    ">$q_{\\phi}(a_t|x_t)$ is a deep neural network that maps xt to the mean and the diagonal covariance of a Gaussian distribution.  \n",
    "\n",
    "LGSSM:  \n",
    "$p_{\\gamma_{t}}\\left(\\mathbf{z}_{t} | \\mathbf{z}_{t-1}, \\mathbf{u}_{t}\\right)=\\mathcal{N}\\left(\\mathbf{z}_{t} ; \\mathbf{A}_{t} \\mathbf{z}_{t-1}+\\mathbf{B}_{t} \\mathbf{u}_{t}, \\mathbf{Q}\\right), \\quad p_{\\gamma_{t}}\\left(\\mathbf{a}_{t} | \\mathbf{z}_{t}\\right)=\\mathcal{N}\\left(\\mathbf{a}_{t} ; \\mathbf{C}_{t} \\mathbf{z}_{t}, \\mathbf{R}\\right)$ (equation (1) in the paper)\n",
    "\n",
    "$p_{\\gamma}(\\mathbf{a}, \\mathbf{z} | \\mathbf{u})=\\prod_{t=1}^{T} p_{\\gamma_{t}}\\left(\\mathbf{a}_{0: t-1}\\right)\\left(\\mathbf{a}_{t} | \\mathbf{z}_{t}\\right) \\cdot p\\left(\\mathbf{z}_{1}\\right) \\prod_{t=2}^{T} p_{\\gamma_{t}\\left(\\mathbf{a}_{0: t-1}\\right)}\\left(\\mathbf{z}_{t} | \\mathbf{z}_{t-1}, \\mathbf{u}_{t}\\right)$ (equation (8) in the paper)\n",
    "\n",
    "dynamics parameter network: \n",
    "${\\bf \\alpha}_t = {\\bf \\alpha}_t(a_{0:t-1})$  \n",
    "${\\bf d}_t = LSTM(a_{t-1}, d_{t-1})$  \n",
    "${\\bf \\alpha}_t = softmax({\\bf d}_t)$\n",
    "$\\mathbf{A}_{t}=\\sum_{k=1}^{K} \\alpha_{t}^{(k)}\\left(\\mathbf{a}_{0: t-1}\\right) \\mathbf{A}^{(k)}, \\quad \\mathbf{B}_{t}=\\sum_{k=1}^{K} \\alpha_{t}^{(k)}\\left(\\mathbf{a}_{0: t-1}\\right) \\mathbf{B}^{(k)}, \\quad \\mathbf{C}_{t}=\\sum_{k=1}^{K} \\alpha_{t}^{(k)}\\left(\\mathbf{a}_{0: t-1}\\right) \\mathbf{C}^{(k)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Loss function\n",
    "$\\mathcal{F}(\\theta, \\gamma, \\phi)=\\mathbb{E}_{q_{\\phi}(\\mathbf{a} | \\mathbf{x})}\\left[\\log \\frac{p_{\\theta}(\\mathbf{x} | \\mathbf{a})}{q_{\\phi}(\\mathbf{a} | \\mathbf{x})}+\\mathbb{E}_{p_{\\gamma}(\\mathbf{z} | \\mathbf{a}, \\mathbf{u})}\\left[\\log \\frac{p_{\\gamma}(\\mathbf{a} | \\mathbf{z}) p_{\\gamma}(\\mathbf{z} | \\mathbf{u})}{p_{\\gamma}(\\mathbf{z} | \\mathbf{a}, \\mathbf{u})}\\right]\\right]$ (euqation (6) in the paper)\n",
    "\n",
    "$\\hat{\\mathcal{F}}(\\theta, \\gamma, \\phi)=\\frac{1}{I} \\sum_{i} \\log p_{\\theta}\\left(\\mathbf{x} | \\widetilde{\\mathbf{a}}^{(i)}\\right)+\\log p_{\\gamma}\\left(\\widetilde{\\mathbf{a}}^{(i)}, \\widetilde{\\mathbf{z}}^{(i)} | \\mathbf{u}\\right)-\\log q_{\\phi}\\left(\\widetilde{\\mathbf{a}}^{(i)} | \\mathbf{x}\\right)-\\log p_{\\gamma}\\left(\\widetilde{\\mathbf{z}}^{(i)} | \\widetilde{\\mathbf{a}}^{(i)}, \\mathbf{u}\\right)$ (euqation (7) in the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
